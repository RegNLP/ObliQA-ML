{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPTLkJPzaQ9fk8+I8KiOoKc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RegNLP/ObliQA-ML/blob/main/ObliQA_ML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# Colab Cell 1 â–¶ï¸ Mount Drive & Enter Project Folder\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# change this to wherever your repo lives in Drive\n",
        "%cd /content/drive/MyDrive/ObliQA-MultiPassage\n"
      ],
      "metadata": {
        "id": "DARHOFOg2IFJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# Colab Cell 2 â–¶ï¸ Install Dependencies\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "!pip install --upgrade openai pandas\n"
      ],
      "metadata": {
        "id": "nQxro64b2ICJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# Colab Cell 3 â–¶ï¸ Imports & Configuration\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "import hashlib, json, os, time, random\n",
        "from datetime import datetime\n",
        "import openai\n",
        "\n",
        "# â€”â€”â€”â€”â€” CONFIGURATION â€”â€”â€”â€”â€”\n",
        "INPUT_JSON          = \"ObliQA_MultiPassage.json\"\n",
        "OUTPUT_JSON         = \"ObliQA_Validated_MultiPassage.json\"\n",
        "OUTPUT_JSONL        = \"ObliQA_Validated_MultiPassage.jsonl\"\n",
        "CACHE_JSON          = \"ObliQA_Validation_Cache.json\"\n",
        "BATCH_PROGRESS_JSON = \"Batch_Progress.json\"\n",
        "\n",
        "MODEL        = \"gpt-4.1-2025-04-14\"\n",
        "SAMPLE_SIZE  = None        # or an int for debugging\n",
        "SLEEP_RANGE  = (1, 3)\n",
        "FLUSH_EVERY  = 5\n",
        "\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")  # or set directly here\n",
        "TOTAL_QS = len(json.load(open(INPUT_JSON, \"r\")))\n"
      ],
      "metadata": {
        "id": "y_Rg64062H_J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# Colab Cell 4 â–¶ï¸ Utility Functions\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "def compute_cache_key(qid, pid):\n",
        "    return hashlib.sha256(f\"{qid}|{pid}\".encode()).hexdigest()\n",
        "\n",
        "def load_json(path):\n",
        "    return json.load(open(path)) if os.path.exists(path) else {}\n",
        "\n",
        "def save_json(data, path):\n",
        "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(data, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "def append_jsonl(entry, path):\n",
        "    with open(path, \"a\", encoding=\"utf-8\") as f:\n",
        "        f.write(json.dumps(entry, ensure_ascii=False) + \"\\n\")\n",
        "\n",
        "def flush_jsonl(jsonl_path, json_path):\n",
        "    arr = []\n",
        "    with open(jsonl_path, \"r\") as f:\n",
        "        for line in f:\n",
        "            try: arr.append(json.loads(line))\n",
        "            except: pass\n",
        "    save_json(arr, json_path)\n",
        "    print(f\"[{datetime.now()}] Flushed {len(arr)} entries â†’ {json_path}\")\n",
        "\n",
        "def retry(fn, retries=3, backoff=1.0):\n",
        "    for i in range(retries):\n",
        "        try: return fn()\n",
        "        except Exception:\n",
        "            if i < retries-1: time.sleep(backoff * 2**i)\n",
        "            else: raise\n",
        "\n",
        "def get_done_ids(path):\n",
        "    s = set()\n",
        "    if os.path.exists(path):\n",
        "        with open(path) as f:\n",
        "            for L in f:\n",
        "                try: s.add(json.loads(L)[\"QuestionID\"])\n",
        "                except: pass\n",
        "    return s\n",
        "\n",
        "def count_done():\n",
        "    return sum(1 for _ in open(OUTPUT_JSONL)) if os.path.exists(OUTPUT_JSONL) else 0\n",
        "\n",
        "def update_progress(total, done, batch):\n",
        "    prog = {\n",
        "        \"total\": total,\n",
        "        \"validated\": done,\n",
        "        \"remaining\": total - done,\n",
        "        \"last_batch\": batch,\n",
        "        \"updated\": datetime.now().isoformat()\n",
        "    }\n",
        "    save_json(prog, BATCH_PROGRESS_JSON)\n",
        "\n",
        "def show_progress():\n",
        "    if not os.path.exists(BATCH_PROGRESS_JSON): return\n",
        "    p = json.load(open(BATCH_PROGRESS_JSON))\n",
        "    print(f\"âœ”ï¸ Total: {p['total']}, Validated: {p['validated']}, Remaining: {p['remaining']}, Last Batch: {p['last_batch']} ({p['updated']})\")\n"
      ],
      "metadata": {
        "id": "EP_0EZBG2H53"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# Colab Cell 5 â–¶ï¸ Validation Logic\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "SYSTEM = \"\"\"\n",
        "You are validating if a Passage answers a Question.\n",
        "Reply only with JSON:\n",
        "{ \"Connection\": \"Directly Connected\"|\"Indirectly Connected\"|\"Not Connected\",\n",
        "  \"ShortReason\": \"...\" }\n",
        "\"\"\"\n",
        "\n",
        "def validate_conn(question, passage):\n",
        "    prompt = f\"Question:\\n{question}\\n\\nPassage:\\n{passage}\"\n",
        "    def call():\n",
        "        return openai.ChatCompletion.create(\n",
        "            model=MODEL,\n",
        "            messages=[\n",
        "                {\"role\":\"system\",\"content\":SYSTEM},\n",
        "                {\"role\":\"user\",  \"content\":prompt}\n",
        "            ],\n",
        "            temperature=0,\n",
        "            max_tokens=512\n",
        "        )\n",
        "    resp = retry(call)\n",
        "    raw = resp.choices[0].message.content.strip()\n",
        "    try:\n",
        "        r = json.loads(raw)\n",
        "        if \"Connection\" in r: return r\n",
        "    except:\n",
        "        pass\n",
        "    return {\"Connection\":\"Not Connected\",\"ShortReason\":\"Parse failed\"}\n"
      ],
      "metadata": {
        "id": "uM5raa4p2HyD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BAI5gkOV2E5x"
      },
      "outputs": [],
      "source": [
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# Colab Cell 6 â–¶ï¸ Main Loop\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "def main():\n",
        "    if not openai.api_key:\n",
        "        raise RuntimeError(\"Set OPENAI_API_KEY!\")\n",
        "    os.makedirs(os.path.dirname(OUTPUT_JSON), exist_ok=True)\n",
        "    os.makedirs(os.path.dirname(CACHE_JSON), exist_ok=True)\n",
        "\n",
        "    cache = load_json(CACHE_JSON)\n",
        "    all_qs = json.load(open(INPUT_JSON))\n",
        "    done_ids = get_done_ids(OUTPUT_JSONL)\n",
        "    to_do = [q for q in all_qs if q[\"QuestionID\"] not in done_ids]\n",
        "    if SAMPLE_SIZE: to_do = random.sample(to_do, SAMPLE_SIZE)\n",
        "\n",
        "    print(f\"ğŸ” {len(to_do)} questions to validate\")\n",
        "    processed = 0\n",
        "\n",
        "    for i, item in enumerate(to_do, 1):\n",
        "        new_passages = []\n",
        "        for p in item[\"Passages\"]:\n",
        "            key = compute_cache_key(item[\"QuestionID\"], f\"{p['DocumentID']}#{p['PassageID']}\")\n",
        "            if key in cache:\n",
        "                result = cache[key]\n",
        "            else:\n",
        "                result = validate_conn(item[\"Question\"], p[\"Passage\"])\n",
        "                cache[key] = result\n",
        "                save_json(cache, CACHE_JSON)\n",
        "            new_passages.append({**p, **result})\n",
        "\n",
        "        append_jsonl({\n",
        "            \"QuestionID\": item[\"QuestionID\"],\n",
        "            \"Question\": item[\"Question\"],\n",
        "            \"Passages\": new_passages\n",
        "        }, OUTPUT_JSONL)\n",
        "\n",
        "        processed += 1\n",
        "        print(f\"[{datetime.now()}] âœ… {i}/{len(to_do)}\")\n",
        "\n",
        "        if i % FLUSH_EVERY == 0:\n",
        "            flush_jsonl(OUTPUT_JSONL, OUTPUT_JSON)\n",
        "\n",
        "        time.sleep(random.uniform(*SLEEP_RANGE))\n",
        "\n",
        "    flush_jsonl(OUTPUT_JSONL, OUTPUT_JSON)\n",
        "    update_progress(TOTAL_QS, count_done(), processed)\n",
        "    print(\"\\nğŸ Done!\")\n",
        "    show_progress()\n",
        "\n",
        "if __name__==\"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# Colab Cell 7 â–¶ï¸ Dataset Statistics\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "import json\n",
        "from collections import Counter\n",
        "\n",
        "# Load the full validated dataset\n",
        "with open(OUTPUT_JSON, \"r\", encoding=\"utf-8\") as f:\n",
        "    validated = json.load(f)\n",
        "\n",
        "# 1) Distribution of number of passages per question\n",
        "passage_counts = Counter(len(item[\"Passages\"]) for item in validated)\n",
        "print(\"ğŸ“Š Questions by # of passages:\")\n",
        "for num_passages in sorted(passage_counts):\n",
        "    print(f\"- {passage_counts[num_passages]:5d} questions have {num_passages} passages\")\n",
        "\n",
        "# 2) Overall totals\n",
        "total_qs = len(validated)\n",
        "total_passages = sum(passage_counts[num] * num for num in passage_counts)\n",
        "print(f\"\\nTotal Questions: {total_qs}\")\n",
        "print(f\"Total Passages  : {total_passages}\")\n"
      ],
      "metadata": {
        "id": "pLc6Ovzn3PDr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# Colab Cell 8 â–¶ï¸ Split into Train/Val/Test\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "import random\n",
        "import json\n",
        "\n",
        "# Shuffle for randomness\n",
        "random.shuffle(validated)\n",
        "\n",
        "total = len(validated)\n",
        "train_end = int(0.70 * total)\n",
        "val_end   = train_end + int(0.15 * total)\n",
        "\n",
        "train_set = validated[:train_end]\n",
        "val_set   = validated[train_end:val_end]\n",
        "test_set  = validated[val_end:]\n",
        "\n",
        "# Save splits\n",
        "with open(\"ObliQA_MultiPassage_train.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(train_set, f, ensure_ascii=False, indent=2)\n",
        "with open(\"ObliQA_MultiPassage_val.json\",   \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(val_set,   f, ensure_ascii=False, indent=2)\n",
        "with open(\"ObliQA_MultiPassage_test.json\",  \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(test_set,  f, ensure_ascii=False, indent=2)\n",
        "\n",
        "print(f\"âœ… Split complete:\")\n",
        "print(f\"- Train:      {len(train_set)} ({len(train_set)/total:.2%})\")\n",
        "print(f\"- Validation: {len(val_set)} ({len(val_set)/total:.2%})\")\n",
        "print(f\"- Test:       {len(test_set)} ({len(test_set)/total:.2%})\")\n"
      ],
      "metadata": {
        "id": "w6HFJKGs3VJY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}